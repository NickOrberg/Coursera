{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем входные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_raw = pd.read_csv(\"features.csv\")\n",
    "X_test_raw = pd.read_csv(\"features_test.csv\")\n",
    "\n",
    "X_train = X_train_raw\n",
    "X_test = X_test_raw\n",
    "y = X_train[\"radiant_win\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подход 1: градиентный бустинг \"в лоб\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Удаялем признаки, связанные с итогами матчей (в test их нет, поэтому удаляем только из train, кэп)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\n",
    "        'tower_status_radiant',\n",
    "        'duration',\n",
    "        'tower_status_dire',\n",
    "        'radiant_win',\n",
    "        'barracks_status_dire',\n",
    "        'barracks_status_radiant'\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Проверяем выборку на наличие NaN. Считаем их количество. Выделяем признаки, в которых они имеются. Пытаемся объяснить их наличие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = pd.concat((X_train, X_test), axis=0) # т.к. нас интересует вся выборка, объединяем train и test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании говорится про ф-цию \"count()\", но по-моему \"isnull()\" - куда удобнее. Получаем количество nan по каждому из признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_player2            51753\n",
      "radiant_flying_courier_time    32364\n",
      "dire_flying_courier_time       30622\n",
      "first_blood_player1            23105\n",
      "first_blood_team               23105\n",
      "first_blood_time               23105\n",
      "dire_bottle_time               18985\n",
      "radiant_bottle_time            18586\n",
      "radiant_first_ward_time         2166\n",
      "dire_first_ward_time            2089\n",
      "radiant_courier_time             819\n",
      "dire_courier_time                806\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sum_nan_by_column = X_all.isnull().sum()\n",
    "sum_nan_by_column = sum_nan_by_column[sum_nan_by_column > 0]\n",
    "sum_nan_by_column = sum_nan_by_column.sort_values(ascending=False)\n",
    "print(sum_nan_by_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В абсолютных величинах это выглядит не очень репрезентативно, перейдем к относительным. <br/>\n",
    "Посчитаем сколько NaN в % во всей выборке и в каждом признаке отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage NaN in X           : 1.930639\n",
      "\n",
      "Percentage NaN by column\n",
      "first_blood_player2           : 45.235868\n",
      "radiant_flying_courier_time   : 28.288479\n",
      "dire_flying_courier_time      : 26.765845\n",
      "first_blood_player1           : 20.195443\n",
      "first_blood_team              : 20.195443\n",
      "first_blood_time              : 20.195443\n",
      "dire_bottle_time              : 16.594264\n",
      "radiant_bottle_time           : 16.245509\n",
      "radiant_first_ward_time       : 1.893241\n",
      "dire_first_ward_time          : 1.825937\n",
      "radiant_courier_time          : 0.715865\n",
      "dire_courier_time             : 0.704502\n"
     ]
    }
   ],
   "source": [
    "perc_nan_in_X = sum_nan_by_column.sum() / (X_all.shape[0] * X_all.shape[1])\n",
    "print(\"%-30s: %f\" % (\"Percentage NaN in X\", perc_nan_in_X * 100.0))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Percentage NaN by column\")\n",
    "\n",
    "len_rows = len(X_all)\n",
    "for i in range(len(sum_nan_by_column)):\n",
    "    print(\"%-30s: %f\" % (sum_nan_by_column.keys()[i], (sum_nan_by_column[i] / len_rows)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно относительно всей выборки число NaN не так уж велико - 1.93%. А вот для отдельных признаков весьма... <br/>\n",
    "Касательно природы появления NaN: <br/>\n",
    "\n",
    "- \"first_blood_player2\" (45% NaN) - по данному признаку ставится NaN, в случае если оно не успело произойти за время измерения(первые 5 минут). Поэтому можно сделать вывод, что данное событие происходит не часто или не так быстро, относительно начала игры. Пытливый data scientist задумается, а почему по \"first_blood_player2\" более чем в два раза (45% vs 20%) больше NaN, чем по \"first_blood_player1\"? Я думаю это связано с тем, что второй (и другие игроки) не всегда бывают причастны к этому событию.<br/><br/>\n",
    "- \"radiant_flying_courier_time\" (28% NaN) - тут все просто: данный предмет не был приобретен за первые 5 минут.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Заполняем пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.1** Нулями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.2** Чем-то очень большим|маленьким (для деревьев все пропуски уйдут в отдельную вершину)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.3** Чем-то средним (среднее, медиана, мода)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Целевую переменную (исход матча) **radiant_win** положили в переменную **y** ранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230,) (97230, 103)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Обучение модели. Попробуем количество деревьев от 10 до 50 с шагом в 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N trees: 10.0 Score: 0.664038510869 Time elapsed: 0:00:46.638668\n",
      "N trees: 20.0 Score: 0.682470555294 Time elapsed: 0:01:35.881484\n",
      "N trees: 30.0 Score: 0.689438923221 Time elapsed: 0:02:45.735480\n",
      "N trees: 40.0 Score: 0.694169429123 Time elapsed: 0:04:28.299346\n",
      "N trees: 50.0 Score: 0.697676711145 Time elapsed: 0:05:07.358580\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(len(X_train), shuffle=True, n_folds=5, random_state=32)\n",
    "n_estimators_variants = np.linspace(10, 50, num=5)\n",
    "n_estimators_scores = list(range(len(n_estimators_variants)))\n",
    "\n",
    "for i, n_estimators in enumerate(n_estimators_variants):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = GradientBoostingClassifier(n_estimators=int(n_estimators), random_state=32)\n",
    "    scores = cross_val_score(model, X_train, y=y, cv=cv, scoring='roc_auc')\n",
    "    n_estimators_scores[i] = scores.mean()\n",
    "    print('N trees:', n_estimators, \n",
    "          'Score:', n_estimators_scores[i], \n",
    "          'Time elapsed:', datetime.datetime.now() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение, кросс-валидация и оценка - происходили за приемлемое время. Результаты и время расчетов приведены выше.<br/>\n",
    "Для обучения 30 деревьев нам потребовалось около 2.5 минут, при этом на кросс-валидации согласно метрике качества AUC-ROC получилось ~ 0.69. Значение **n_estimators=30** можно считать оптимальным. Так как, при его увеличении качество увеличивается незначительно, относительно времени вычислений. Ускорить обучение можно следующим образом: использовать методы понижения размерности (PCA), обучаться на случайном подмножестве выборки, ограничить глубину дерева, использовать библиотеки, включающие методы параллельных вычисление (XGBoost). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подход 2: логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Обучаем модель и подбираем коэффициент регуляризации (C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y):\n",
    "    X_train_scaled = scale(X_train)\n",
    "    cv = KFold(len(X_train), shuffle=True, n_folds=5, random_state=32)\n",
    "    C_variants = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    C_scores = list(range(len(C_variants)))\n",
    "    for i, C in enumerate(C_variants):\n",
    "        start_time = datetime.datetime.now()\n",
    "        model = LogisticRegression(penalty='l2', C=C, random_state=32)\n",
    "        scores = cross_val_score(model, X_train_scaled, y=y, cv=cv, scoring='roc_auc')\n",
    "        C_scores[i] = scores.mean()\n",
    "        print(\"%-5s %-15f %-5s %-15f %-5s %s\" % ('C value:', C, \n",
    "                                      'Score:', C_scores[i],\n",
    "                                      'Time elapsed:', datetime.datetime.now() - start_time))\n",
    "    best_score = max(C_scores)\n",
    "    best_C = C_variants[C_scores.index(best_score)]\n",
    "    print(\"\")\n",
    "    print(\"Best C value:\", best_C, 'Score:', best_score)\n",
    "    return best_score, best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value: 0.000010        Score: 0.695115        Time elapsed: 0:00:03.087176\n",
      "C value: 0.000100        Score: 0.711304        Time elapsed: 0:00:04.492257\n",
      "C value: 0.001000        Score: 0.716346        Time elapsed: 0:00:07.681440\n",
      "C value: 0.010000        Score: 0.716562        Time elapsed: 0:00:10.207584\n",
      "C value: 0.100000        Score: 0.716544        Time elapsed: 0:00:10.480599\n",
      "C value: 1.000000        Score: 0.716540        Time elapsed: 0:00:10.381593\n",
      "C value: 10.000000       Score: 0.716540        Time elapsed: 0:00:12.172697\n",
      "C value: 100.000000      Score: 0.716540        Time elapsed: 0:00:11.892680\n",
      "C value: 1000.000000     Score: 0.716540        Time elapsed: 0:00:11.982685\n",
      "\n",
      "Best C value: 0.01 Score: 0.716561747302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\Desktop\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "best_score, best_C = train_logistic_regression(X_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество (~0.72) достигается при C=0.01, что немного лучше, в сравнении с бустингом проведенным ранее. Расчеты выполняется быстрее, это наглядно видно выше. Улучшение качетсва может быть обусловлено следующими причинами:<br/>\n",
    "- В сравнение с логистического регрессией, решающие деревья более подвержены переобучению, но этого можно избежать использую прунинг.\n",
    "- Решающие деревья основываются на том, что разделющие гиперплоскости будут строго параллельны координатным осям, а логистическая регрессия не имеет такого предположения. Поэтому можно сделать вывод, что выборка разделяется \"линейной\" гиперплоскостью, не являющейся параллельной осям, лучше, чем множеством гиперплоскостей параллельных осям координат.<br/>\n",
    "\n",
    "*Источник: https://www.quora.com/What-are-the-advantages-of-logistic-regression-over-decision-trees *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Убираем категориальные признаки и заново обучаемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\n",
    "        'lobby_type',\n",
    "        'r1_hero',\n",
    "        'r2_hero',\n",
    "        'r3_hero',\n",
    "        'r4_hero',\n",
    "        'r5_hero',\n",
    "        'd1_hero',\n",
    "        'd2_hero',\n",
    "        'd3_hero',\n",
    "        'd4_hero',\n",
    "        'd5_hero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value: 0.000010        Score: 0.695066        Time elapsed: 0:00:02.480142\n",
      "C value: 0.000100        Score: 0.711306        Time elapsed: 0:00:03.728213\n",
      "C value: 0.001000        Score: 0.716394        Time elapsed: 0:00:06.981399\n",
      "C value: 0.010000        Score: 0.716608        Time elapsed: 0:00:09.435540\n",
      "C value: 0.100000        Score: 0.716589        Time elapsed: 0:00:10.140580\n",
      "C value: 1.000000        Score: 0.716585        Time elapsed: 0:00:10.131579\n",
      "C value: 10.000000       Score: 0.716584        Time elapsed: 0:00:10.113579\n",
      "C value: 100.000000      Score: 0.716584        Time elapsed: 0:00:10.051575\n",
      "C value: 1000.000000     Score: 0.716584        Time elapsed: 0:00:10.052575\n",
      "\n",
      "Best C value: 0.01 Score: 0.71660786983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\Desktop\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "best_score, best_C = train_logistic_regression(X_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "После удаления категориальных признаков качество немного возросло (0.7165 vs 0.7166), при этом Best C Value=0.01 осталось прежним. Объяснить данное улучшение можно следующим образом:<br/>\n",
    "- *\"lobby_type\"* - тип комнаты, в которой собираются игроки, носит чисто формальный характер, так как в описании процесса игры я не нашел информации о влиянии типа выбранной комнаты на механику игры.\n",
    "- *\"r|d_1-5_hero\"* - тип соответствующего игрока. Наверняка есть определенные стратегии(правила) выбора игроков и запрета выбора для другой команды (определяемые игроками или внутренними механизмами игры), которые не позволяют получить значимый перевес одной из команд при выборе игроков и существенным образом повлиять на исход матча. То есть, разумеется, наверняка, есть такие типы игроков, которые выигрывают чаще чем другие, но мы ведь рассматриваем не просто одного игрока, а их комбинацию, потому и их значимость начинает шуметь. Возможно, стоит формировать фичи из самых часто встречающихся комбинаций и работать уже с ними.<br/>\n",
    "\n",
    "Таким образом, влияние данных признаков можно считать несущественным, что и подтверждают результаты обучения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Считаем типы героев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "heroes = X_all[[\n",
    "        'r1_hero',\n",
    "        'r2_hero',\n",
    "        'r3_hero',\n",
    "        'r4_hero',\n",
    "        'r5_hero',\n",
    "        'd1_hero',\n",
    "        'd2_hero',\n",
    "        'd3_hero',\n",
    "        'd4_hero',\n",
    "        'd5_hero']]\n",
    "\n",
    "heroes = heroes.dropna()\n",
    "unic_heroes = pd.Series(heroes.values.ravel()).unique()\n",
    "print(len(unic_heroes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Получили 108 уникальных типов героев. Однако если посмотреть файл \"heroes.csv\", то там их **112** (последний индекс 113, но строчек 112). Значит какие-то герои не очень популярны =)<br/>\n",
    "*Проверка: http://dota2.gamepedia.com/Heroes_by_release*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**4.** Кодирование информации о героях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_raw.drop([\n",
    "        'tower_status_radiant',\n",
    "        'duration',\n",
    "        'tower_status_dire',\n",
    "        'radiant_win',\n",
    "        'barracks_status_dire',\n",
    "        'barracks_status_radiant',\n",
    "        'lobby_type'], axis=1)\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "def get_hero_features(X):\n",
    "    heros_amount = 112\n",
    "    X_pick = np.zeros((X.shape[0], heros_amount))\n",
    "    for i, match_id in enumerate(X.index):\n",
    "        for p in range(5):\n",
    "            X_pick[i, X.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "            X_pick[i, X.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "    X_pick_df = pd.DataFrame(X_pick, columns=['hero_' + str(n) for n in range(1, heros_amount + 1)])\n",
    "    return X_pick_df\n",
    "\n",
    "X_train = pd.concat((X_train, get_hero_features(X_train)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**5.** Проведем кросс-валидацию на новой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value: 0.000010        Score: 0.714910        Time elapsed: 0:00:04.333248\n",
      "C value: 0.000100        Score: 0.742964        Time elapsed: 0:00:06.960398\n",
      "C value: 0.001000        Score: 0.751864        Time elapsed: 0:00:13.331762\n",
      "C value: 0.010000        Score: 0.752191        Time elapsed: 0:00:18.354050\n",
      "C value: 0.100000        Score: 0.752154        Time elapsed: 0:00:19.976143\n",
      "C value: 1.000000        Score: 0.752147        Time elapsed: 0:00:20.781188\n",
      "C value: 10.000000       Score: 0.752147        Time elapsed: 0:00:20.815191\n",
      "C value: 100.000000      Score: 0.752147        Time elapsed: 0:00:20.812191\n",
      "C value: 1000.000000     Score: 0.752147        Time elapsed: 0:00:20.795190\n",
      "\n",
      "Best C value: 0.01 Score: 0.752190530631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\Desktop\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "best_score, best_C = train_logistic_regression(X_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество выросло: **0.717 vs 0.752**. Раньше алгоритм пытался разделить выборку на два класса в пространстве, значения которого были от 1 до 112, воспринимая их как непрерывную величину. Что является не совсем верным, относительно природы данного признака, так как его значения являются категориальными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Строим предсказания вероятностей победы команды Radiant для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\Desktop\\WinPython-64bit-3.4.4.1\\python-3.4.4.amd64\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.drop('lobby_type', axis=1)\n",
    "X_test = pd.concat((X_test, get_hero_features(X_test)), axis=1)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', C=0.01, random_state=32)\n",
    "clf.fit(scale(X_train), y)\n",
    "predictions = clf.predict_proba(scale(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальное значение предсказания  : 0.003591\n",
      "Максимальное значение предсказания : 0.996409\n"
     ]
    }
   ],
   "source": [
    "print(\"%-35s: %f\" % ('Минимальное значение предсказания', predictions.min()))\n",
    "print(\"%-35s: %f\" % ('Максимальное значение предсказания', predictions.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
